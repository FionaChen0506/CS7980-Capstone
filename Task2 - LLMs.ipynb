{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fae71e9-b635-46ef-90dc-2160facba4c9",
   "metadata": {},
   "source": [
    "## Review Correlation Analysis - LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b680eff-8bf7-4acc-ade9-17e20f4a0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets scikit-learn pandas numpy matplotlib tqdm evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f536668-74a9-4539-9df5-fa4f688edadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.21.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a177778-1d4d-4376-95e1-2a69d49cdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c8e0d0-e697-4d9d-b0ce-e365f84cb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "import evaluate\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4b82f3-e5d2-47bf-a860-ee6f860d97b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 11 05:19:52 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              72W / 500W |   6722MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     11221      C   ...entos7/anaconda3/2022.05/bin/python     6708MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7093f042-6054-46f6-a011-87a093b7c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Books\", \"Music\", \"Video\", \"Toys\", \"Tools\", \"Office Products\",\n",
    "        \"Electronics\", \"Kitchen\", \"Sports\", \"Shoes\",\n",
    "        \"Health & Personal Care\"]\n",
    "\n",
    "id2label = {0: \"Books\", 1: \"Music\", 2: \"Video\", 3: \"Toys\", 4: \"Tools\", \n",
    "        5: \"Office Products\", 6: \"Electronics\", 7: \"Kitchen\", 8: \"Sports\",\n",
    "        9: \"Shoes\", 10: \"Health & Personal Care\"}\n",
    "\n",
    "label2id = {\"Books\": 0, \"Music\": 1, \"Video\":2, \"Toys\": 3, \"Tools\": 4, \"Office Products\": 5,\n",
    "        \"Electronics\": 6, \"Kitchen\": 7, \"Sports\": 8, \"Shoes\": 9,\n",
    "        \"Health & Personal Care\": 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff0b12a-588f-4369-af46-9c81b19a8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "data_files = {\n",
    "        \"test\": 'amazon_prod_review_cls_test.json'    # test json path\n",
    "    }\n",
    "    \n",
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d58dcf9-f671-46d3-b418-d56e46effd7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### define LLM correlation anaylsis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76d71b8-ddcc-4bb9-960b-7f96a1c31df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def pipeline_corr_eval_llm(pipe, data, template, label2id):\n",
    "    res_dict = {}\n",
    "    correct = [0 for _ in range(11)]\n",
    "    correct_top2 = [0 for _ in range(11)]\n",
    "    correct_top3 = [0 for _ in range(11)]\n",
    "    \n",
    "    total = [0 for _ in range(11)]\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    incorrect = []\n",
    "    fp = [0 for _ in range(11)]\n",
    "    fn = [0 for _ in range(11)]\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i, row in tqdm(enumerate(data), total=len(data)):\n",
    "        text = row['text']\n",
    "        label = int(row['label'])\n",
    "        prompt = template.format(text = text)\n",
    "        result = pipe(prompt)[0]\n",
    "\n",
    "        # Extracting prediction types from generated_text\n",
    "        pred_types_raw = result['generated_text']\n",
    "    \n",
    "        # Keep only the part after ':' for each prediction type and join them\n",
    "        pred_types_joined = ', '.join([pt.split(':', 1)[1].strip() if ':' in pt else pt for pt in pred_types_raw.split(', ')])\n",
    "\n",
    "        # Now split the joined string by ','\n",
    "        pred_types = pred_types_joined.split(', ')\n",
    "\n",
    "        pred_ids = []\n",
    "        \n",
    "        # get rid of pred_type which is not in the label_space\n",
    "        for pt in pred_types:\n",
    "            try:\n",
    "                pred_id = int(label2id[pt])\n",
    "                pred_ids.append(pred_id)\n",
    "            except KeyError:\n",
    "                pred_ids.append(99)\n",
    "\n",
    "        \n",
    "        result['Id'] = row['Id']\n",
    "        \n",
    "        res_dict[i] = {'Id': row['Id'], 'pred':result['generated_text']}\n",
    "        \n",
    "        preds.append(pred_ids)\n",
    "        labels.append(label)\n",
    "        \n",
    "        total[label] += 1\n",
    "        # Check for correct predictions\n",
    "        # Check for correct top 1 prediction\n",
    "        if pred_ids and label == pred_ids[0]:\n",
    "            correct[label] += 1\n",
    "\n",
    "        # Check for correct top 2 predictions\n",
    "        if len(pred_ids) > 1 and label in pred_ids[:2]:\n",
    "            correct_top2[label] += 1\n",
    "\n",
    "        # Check for correct top 3 predictions\n",
    "        if len(pred_ids) > 2 and label in pred_ids[:3]:\n",
    "            correct_top3[label] += 1\n",
    "        \n",
    "        # if label not in pred_ids[:3]:\n",
    "        #     d = {\"pred\": [id2label[pred] for pred in list(correct_top3)], \n",
    "        #            \"label\": label, \"review\": text, \"probability\": str(probs)}\n",
    "        #     incorrect.append(d)\n",
    "        \n",
    "        if label != pred_ids[0]:\n",
    "            fp[pred_ids[0]] += 1\n",
    "            fn[label] += 1\n",
    "    \n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    out_dict = {}\n",
    "    out_dict['res_corr'] = res_dict\n",
    "    out_dict['correct_corr'] = correct\n",
    "    out_dict['correct_corr_top2'] = correct_top2\n",
    "    out_dict['correct_corr_top3'] = correct_top3\n",
    "    out_dict['total_corr'] = total\n",
    "    out_dict['runtime_corr'] = runtime\n",
    "    out_dict['preds'] = preds\n",
    "    out_dict['labels'] = labels\n",
    "    out_dict['incorrect'] = incorrect\n",
    "    out_dict['fp'] = fp\n",
    "    out_dict['fn'] = fn\n",
    "    # return res_dict, correct, correct_top2, correct_top3, total, runtime, preds, labels, incorrect\n",
    "    return out_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e79ac-2f3e-4f67-84b6-fdf36d957fcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### zero-shot inference on FLAN-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b625197a-2cd3-4d32-b3c5-45339c8599d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please perform multi labels classification task.\n",
      "Select the three categories that best fit the content of the review from ['Books', 'Music', 'Video', 'Toys', 'Tools', 'Office Products', 'Electronics', 'Kitchen', 'Sports', 'Shoes', 'Health & Personal Care'].\n",
      "Example: \n",
      "Customer review: 'I loved this thriller novel! It kept me on the edge of my seat.'\n",
      "Output: Books, Electronics, Sports\n",
      "\n",
      "Customer review:\n",
      "{text}.\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "task_name = 'multi labels classification'\n",
    "label_space = [\"Books\", \"Music\", \"Video\", \"Toys\", \"Tools\", \"Office Products\", \"Electronics\", \"Kitchen\", \"Sports\", \"Shoes\", \"Health & Personal Care\"]\n",
    "task_definition = f'Select the three categories that best fit the content of the review from {label_space}.'\n",
    "# output_format = \"top1, top2, top3\"\n",
    "\n",
    "example_output = \"Customer review: 'I loved this thriller novel! It kept me on the edge of my seat.'\\nOutput: Books, Electronics, Sports\"\n",
    "\n",
    "template = f\"Please perform {task_name} task.\\n{task_definition}\\nExample: \\n{example_output}\\n\\nCustomer review:\\n\" + \"{text}.\"\n",
    "\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd010af-b48d-495b-824f-18dbd6754178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5d0a6d351749adad5680d5f0f8beed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flan-T5\n",
    "pipeFlanT5 = pipeline(\n",
    "    \"text2text-generation\", \n",
    "    model=\"google/flan-t5-xxl\", \n",
    "    # device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17848ea-6d53-4a10-abe4-574a2130b087",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeFlanT5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# delete the pipeFlanT5 and free up some memory\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m pipeFlanT5\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#del pipeFlanUL2\u001b[39;00m\n\u001b[1;32m      6\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeFlanT5' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# delete the pipeFlanT5 and free up some memory\n",
    "del pipeFlanT5\n",
    "#del pipeFlanUL2\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bad735c-1b07-48ef-bbfc-09d27d2c840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "/home/li.yunke/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 53\n",
      "Input: This is the remixes for Madonna's newest single \\\\\"American Life\\\\\" and  it vastly improves on the original version. The mixes range from hip hop to trance/electronica to flat out house music. The best mixes of the song are by Missy Elliott,Paul Oakenfold and Part 2 of the Peter Rauhofer American Anthem mix. The Missy Elliott American Dream mix(4:49) is typical Missy and that is saying a lot becuase she is so much a genius. The Paul Oakenfold Downtempo mix(6:32) is the best mix here. It gives Madonna the chance like \\\\\"Justify My Love\\\\\" and  \\\\\"Erotica\\\\\" to get more r&b/rap influenced than normally done. It is very different from his normal type of mix but it works. The Felix Da Housecat Devin Dazzle Mix(6:10) is crap. It tries to move the vocals to a more upbeat type flow and makes her sound weird. The Peter Rauhofer part 1 American Anthem mix(10:41) is electro and does the same vocally as the Felix Da Housecat Mix with a tad better results. His part 2 Mix(9:06) is what will take this song to number one on the club charts. The vocals are at normal speed and she sounds aggressive. The weird thing though is that the original mix -the rap sounds out of place but on the remixes they are to me the highlight--weird ! Then you get the new mix by Richard Humpty Vission of \\\\\"Die Another Day\\\\\"(6:01) that takes the Bond theme into more electro type vibe. That said this is Madonna and is you love her or hate her this cd single is a good feel for what not only Madonna wants to do(She gets final say over all mixes done) but also what is the state of Club music in 2003.\n",
      "Actual Label: Music\n",
      "Output: [{'generated_text': 'Output: Music, Music, Music'}]\n",
      "Runtime: 21.92535090446472\n",
      "\n",
      "Index: 54\n",
      "Input: The Flaming Lips had awesome guitar on their earlier albums, true this one lacks that awesome guitar like they use to have, its a bit more electronic, but so what, its a very cool and unique album. They still use guitars just with a different distortion, because if you're not experimental then everything just sounds the same year after year. Flaming Lips are flippn' awesome. Don't listen to anyone who gives them a bad reveiw, especially if they think the best album ever is Sean Paul - Dutty Rock. Also, the cover of this album is great, very imaginative, but don't judge an album or anything by its cover.<br /><br />Best Songs: Yoshimi Battles the Pink Robots Pt. 1, In the Morning of the Musicians, Fight Test, Do You Realize? and It's Summertime. The rest are great as well.<br /><br />Still I would check these albums out Soft Bulletin, Clouds Taste Metallic, Transmissions..., Hit to Death in the Future Head and a nice little not very known and very underated Oh My Gawd Flaming Lips!!\n",
      "Actual Label: Music\n",
      "Output: [{'generated_text': 'Output: Music, Music, Music'}]\n",
      "Runtime: 17.927491903305054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices_to_test = [101, 201, 301, 401, 501]\n",
    "\n",
    "for index in range(53, 55):\n",
    "    example = test_dataset[index]['text']\n",
    "    actual_label_id = test_dataset[index]['label']\n",
    "    # turn the label into the string according to id2label\n",
    "    actual_label_name = id2label[actual_label_id]\n",
    "    start_time = time.time()\n",
    "    prompt = template.format(text=example)\n",
    "    output = pipeFlanT5(prompt)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f'Index: {index}')\n",
    "    print(f'Input: {example}')\n",
    "    print(f'Actual Label: {actual_label_name}')\n",
    "    # print(f'Prompt: {prompt}')\n",
    "    print(f'Output: {output}')\n",
    "    print(f'Runtime: {end_time - start_time}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcbd5865-e27b-4559-b39d-d58171b75491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> load results from FlanT5_eval_results_task2.json\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./FlanT5_eval_results_task2.json\"):\n",
    "    flant5_out = pipeline_corr_eval_llm(pipeFlanT5, test_dataset, template, label2id)\n",
    "    with open(\"./FlanT5_eval_results_task2.json\", \"w\") as f:\n",
    "        json.dump(flant5_out,f)\n",
    "    print('=> save results to flant5_eval_results_task2.json')\n",
    "else:\n",
    "    with open(\"./FlanT5_eval_results_task2.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        FlanT5_res_corr = data['res_corr']\n",
    "        FlanT5_correct_corr = data['correct_corr']\n",
    "        FlanT5_correct_corr_top2 = data['correct_corr_top2']\n",
    "        FlanT5_correct_corr_top3 = data['correct_corr_top3']\n",
    "        FlanT5_total_corr = data['total_corr']\n",
    "        FlanT5_runtime_corr = data['runtime_corr']\n",
    "        FlanT5_preds = data['preds']\n",
    "        FlanT5_labels = data['labels']\n",
    "        Flant5_incorrect = data['incorrect']\n",
    "        Flant5_fp = data['fp']\n",
    "        Flant5_fn = data['fn']\n",
    "    print('=> load results from FlanT5_eval_results_task2.json')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dec79451-a343-41fa-bb32-25d443cf7b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 0 - Precision: 0.96, Recall: 1.00\n",
      "Category 1 - Precision: 0.96, Recall: 0.98\n",
      "Category 2 - Precision: 0.98, Recall: 1.00\n",
      "Category 3 - Precision: 0.85, Recall: 0.92\n",
      "Category 4 - Precision: 0.47, Recall: 0.82\n",
      "Category 5 - Precision: 0.77, Recall: 0.54\n",
      "Category 6 - Precision: 0.38, Recall: 0.82\n",
      "Category 7 - Precision: 0.74, Recall: 0.40\n",
      "Category 8 - Precision: 1.00, Recall: 0.12\n",
      "Category 9 - Precision: 0.98, Recall: 0.98\n",
      "Category 10 - Precision: 0.59, Recall: 0.32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "correct_corr = flant5_out['correct_corr']  \n",
    "fp = flant5_out['fp']  \n",
    "fn = flant5_out['fn'] \n",
    "\n",
    "precision_per_class = {}\n",
    "recall_per_class = {}\n",
    "\n",
    "for category in range(11): \n",
    "    TP = correct_corr[category]\n",
    "    FP = fp[category]\n",
    "    FN = fn[category]\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN) \n",
    "    \n",
    "    precision_per_class[category] = precision\n",
    "    recall_per_class[category] = recall\n",
    "\n",
    "for category in range(11):\n",
    "    print(f\"Category {category} - Precision: {precision_per_class[category]:.2f}, Recall: {recall_per_class[category]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4988faab-e2f4-4ddf-9ca2-118e3f552e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Books Accuracy: 1.0\n",
      "==> Music Accuracy: 0.98\n",
      "==> Video Accuracy: 1.0\n",
      "==> Toys Accuracy: 0.92\n",
      "==> Tools Accuracy: 0.82\n",
      "==> Office Products Accuracy: 0.54\n",
      "==> Electronics Accuracy: 0.82\n",
      "==> Kitchen Accuracy: 0.4\n",
      "==> Sports Accuracy: 0.12\n",
      "==> Shoes Accuracy: 0.98\n",
      "==> Health & Personal Care Accuracy: 0.32\n",
      "==> Total Accuracy: 0.7181818181818181\n",
      "==> Total Runtime: 7028.367094993591\n"
     ]
    }
   ],
   "source": [
    "# calculate the top-1 accuracy\n",
    "for key,val in id2label.items():\n",
    "    print(f'==> {val} Accuracy: {FlanT5_correct_corr[int(key)]/FlanT5_total_corr[int(key)]}')\n",
    "print(f'==> Total Accuracy: {np.sum(FlanT5_correct_corr) / np.sum(FlanT5_total_corr)}')\n",
    "print(f'==> Total Runtime: {FlanT5_runtime_corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "321997e4-e3a3-4765-9abb-1b5e2ab301a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Books Accuracy: 0.96\n",
      "==> Music Accuracy: 1.0\n",
      "==> Video Accuracy: 0.92\n",
      "==> Toys Accuracy: 0.98\n",
      "==> Tools Accuracy: 1.0\n",
      "==> Office Products Accuracy: 0.68\n",
      "==> Electronics Accuracy: 0.96\n",
      "==> Kitchen Accuracy: 0.78\n",
      "==> Sports Accuracy: 0.42\n",
      "==> Shoes Accuracy: 1.0\n",
      "==> Health & Personal Care Accuracy: 0.64\n",
      "==> Total Accuracy: 0.8490909090909091\n",
      "==> Total Runtime: 212.081848859787\n"
     ]
    }
   ],
   "source": [
    "# calculate the top-2 accuracy\n",
    "for key,val in id2label.items():\n",
    "    print(f'==> {val} Accuracy: {FlanT5_correct_corr_top2[int(key)]/FlanT5_total_corr[int(key)]}')\n",
    "print(f'==> Total Accuracy: {np.sum(FlanT5_correct_corr_top2) / np.sum(FlanT5_total_corr)}')\n",
    "print(f'==> Total Runtime: {FlanT5_runtime_corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabdf018-0fff-42b2-9a11-329fcc37e682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Books Accuracy: 0.96\n",
      "==> Music Accuracy: 1.0\n",
      "==> Video Accuracy: 0.92\n",
      "==> Toys Accuracy: 0.98\n",
      "==> Tools Accuracy: 1.0\n",
      "==> Office Products Accuracy: 0.84\n",
      "==> Electronics Accuracy: 1.0\n",
      "==> Kitchen Accuracy: 0.8\n",
      "==> Sports Accuracy: 0.86\n",
      "==> Shoes Accuracy: 1.0\n",
      "==> Health & Personal Care Accuracy: 0.68\n",
      "==> Total Accuracy: 0.9127272727272727\n",
      "==> Total Runtime: 212.081848859787\n"
     ]
    }
   ],
   "source": [
    "# calculate the top-3 accuracy\n",
    "for key,val in id2label.items():\n",
    "    print(f'==> {val} Accuracy: {FlanT5_correct_corr_top3[int(key)]/FlanT5_total_corr[int(key)]}')\n",
    "print(f'==> Total Accuracy: {np.sum(FlanT5_correct_corr_top3) / np.sum(FlanT5_total_corr)}')\n",
    "print(f'==> Total Runtime: {FlanT5_runtime_corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c63d3-a5b7-413c-8987-2924f63c3bf8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e78e90bf-b532-4772-b05a-93446a77035f",
   "metadata": {},
   "source": [
    "## zero-shot inference on FLAN-UL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "714c48aa-3f45-4cd2-97f1-ad40c207cd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please perform multi labels classification task.\n",
      "Select the three categories that best fit the content of the review from ['Books', 'Music', 'Video', 'Toys', 'Tools', 'Office Products', 'Electronics', 'Kitchen', 'Sports', 'Shoes', 'Health & Personal Care'].\n",
      "Output format: first label, second label, third label\n",
      "Example: \n",
      "Customer review: 'I loved this thriller novel! It kept me on the edge of my seat.'\n",
      "Output: Books, Electronics, Video\n",
      "\n",
      "Customer review:\n",
      "{text}.\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "task_name = 'multi labels classification'\n",
    "label_space = [\"Books\", \"Music\", \"Video\", \"Toys\", \"Tools\", \"Office Products\", \"Electronics\", \"Kitchen\", \"Sports\", \"Shoes\", \"Health & Personal Care\"]\n",
    "task_definition = f'Select the three categories that best fit the content of the review from {label_space}.'\n",
    "output_format = \"Output format: first label, second label, third label\"\n",
    "example_output = \"Customer review: 'I loved this thriller novel! It kept me on the edge of my seat.'\\nOutput: Books, Electronics, Video\"\n",
    "\n",
    "template = f\"Please perform {task_name} task.\\n{task_definition}\\n{output_format}\\nExample: \\n{example_output}\\n\\nCustomer review:\\n\" + \"{text}.\"\n",
    "\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdca8bf9-89c1-4ee6-98e0-346357bb8633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2428237028b425aacd705af5fb966fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# flan-UL2\n",
    "pipeFlanUL2 = pipeline(\"text2text-generation\", model=\"google/flan-ul2\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf0dc2f2-cf8c-4a32-a413-92f462b54d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# delete the pipeFlanT5 and free up some memory\n",
    "# del pipeFlanT5\n",
    "# del pipeFlanUL2\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad60ed0-30f6-4cab-83b5-78bbbd8a7e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 11 04:44:52 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              66W / 500W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532b8b51-e48a-42ed-9b4f-59385ebb54fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.yunke/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 101\n",
      "Input: Julie Andrews and Dick Van Dyke did outstanding jobs in<BR>this timeless Disney classic!Andrews is wonderful as the<BR>kind-hearted yet strict nanny,and Van Dyke's performance<BR>of Burt is very good;Van Dyke's Cockney accent is very well-<BR>performed and convincing!The scenery is colorful and very<BR>well-done,and the performers are superb!David Tomlisin is<BR>perfect as the no-nonsense banker George Banks,and Reginald<BR>Owen is wonderful as the elderly Admiral Boom!And who<BR>can forget songs like the touching&quot;Feed the Birds&quot;or the <BR>lively &quot;Step in Time&quot;?Young and old alike will be entertained<BR>by this film.A must-have for any Disney collection!\n",
      "Actual Label: Video\n",
      "Output: [{'generated_text': 'Output: Video, Video, Video'}]\n",
      "Runtime: 2.044362783432007\n",
      "\n",
      "Index: 201\n",
      "Input: I am happy with this purchase. This would truly be a life-saver in a survival scenario. This is a decent multitool, good flashlight and firesteel.\n",
      "Actual Label: Tools\n",
      "Output: [{'generated_text': 'Output: Tools, Electronics, Office Products'}]\n",
      "Runtime: 0.5662147998809814\n",
      "\n",
      "Index: 301\n",
      "Input: I wonder what makes HDMI cables so costly.  Spending over fifty dollars seems ridiculous to me, so I've been waiting for a reasonably priced, high quality, flexible cable and I found exactly what I needed with the AmazonBasics Braided Ultra High Speed HDMI Cable at 6.5 feet!  Costing substantially less than comparable cables I've researched and held in my hands, this stands heads and shoulders above the others and I'm thrilled to now have my new HDTV hooked up to Cox Cable via this HDMI cable rather than the standard cables provided by the company.  Without an HDMI cable, I was not receiving the full options available but don't regret waiting to get this brand and model from Amazon; I would have spent far much more money to purchase another brand and it likely would not be as flexible and substantial as this.  My television is providing much more entertainment today than it was yesterday and the HD channels are overwhelmingly wonderful now!  Wish I'd utilized the HDMI capability sooner, but I'm happy to have this particular cable now and more money in the wallet for popcorn and beverages.<br /><br />The images provided by Amazon cover just about everything included with the exception of a little black twisty tie.  Nothing is wasted in this packaging, it can be reused or recycled and you do not need tools to access the cable from the packaging.  There is no chemical scent and you'll receive no cuts on the fingers from hard plastic packaging.<br /><br />If you're in the market for a longer braided cable, AmazonBasics also offers a 9.8 Feet model.\n",
      "Actual Label: Electronics\n",
      "Output: [{'generated_text': 'Output: Electronics, Video, Electronics'}]\n",
      "Runtime: 0.9493973255157471\n",
      "\n",
      "Index: 401\n",
      "Input: Bought this for my husband. He used it the other day to batton wood, and said it scared the wood apart!!!\n",
      "Actual Label: Sports\n",
      "Output: [{'generated_text': 'Output: Tools, Toys, Sports'}]\n",
      "Runtime: 0.5532939434051514\n",
      "\n",
      "Index: 501\n",
      "Input: I've tried other BP monitors, and this one far exceeds them all. Easy, comfortable, and easy to read since it's all right there in the Withings App. 😄👍🏻\n",
      "Actual Label: Health & Personal Care\n",
      "Output: [{'generated_text': 'Output: Health & Personal Care, Electronics, Health & Personal Care'}]\n",
      "Runtime: 0.7649979591369629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices_to_test = [101, 201, 301, 401, 501]\n",
    "\n",
    "for index in indices_to_test:\n",
    "    example = test_dataset[index]['text']\n",
    "    actual_label_id = test_dataset[index]['label']\n",
    "    # turn the label into the string according to id2label\n",
    "    actual_label_name = id2label[actual_label_id]\n",
    "    start_time = time.time()\n",
    "    prompt = template.format(text=example)\n",
    "    output = pipeFlanUL2(prompt)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f'Index: {index}')\n",
    "    print(f'Input: {example}')\n",
    "    print(f'Actual Label: {actual_label_name}')\n",
    "    # print(f'Prompt: {prompt}')\n",
    "    print(f'Output: {output}')\n",
    "    print(f'Runtime: {end_time - start_time}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473f7f80-4a47-40c8-a72e-eb035fda9cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f9ec0fb72f4426a701cc4afaab21e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/shared/centos7/anaconda3/2022.05/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_10578/3066290070.py\", line 2, in <cell line: 1>\n",
      "    flanul2_out = pipeline_corr_eval_llm(pipeFlanUL2, test_dataset, template, label2id)\n",
      "  File \"/tmp/ipykernel_10578/2374201777.py\", line 23, in pipeline_corr_eval_llm\n",
      "    result = pipe(prompt)[0]\n",
      "  File \"/home/li.yunke/.local/lib/python3.9/site-packages/transformers/pipelines/text2text_generation.py\", line 167, in __call__\n",
      "    result = super().__call__(*args, **kwargs)\n",
      "  File \"/home/li.yunke/.local/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n",
      "    logger.warning_once(\n",
      "  File \"/home/li.yunke/.local/lib/python3.9/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
      "Arguments: (<class 'UserWarning'>,)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2091 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> save results to FlanUL2_eval_results_task2.json\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./FlanUL2_eval_results_task2.json\"):\n",
    "    flanul2_out = pipeline_corr_eval_llm(pipeFlanUL2, test_dataset, template, label2id)\n",
    "    with open(\"./FlanUL2_eval_results_task2.json\", \"w\") as f:\n",
    "        json.dump(flanul2_out,f)\n",
    "    print('=> save results to FlanUL2_eval_results_task2.json')\n",
    "else:\n",
    "    with open(\"./FlanUL2_eval_results_task2.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        FlanUL2_res_corr = data['res_corr']\n",
    "        FlanUL2_correct_corr = data['correct_corr']\n",
    "        FlanUL2_correct_corr_top2 = data['correct_corr_top2']\n",
    "        FlanUL2_correct_corr_top3 = data['correct_corr_top3']\n",
    "        FlanUL2_total_corr = data['total_corr']\n",
    "        FlanUL2_runtime_corr = data['runtime_corr']\n",
    "        FlanUL2_preds = data['preds']\n",
    "        FlanUL2_labels = data['labels']\n",
    "        FlanUL2_incorrect = data['incorrect']\n",
    "        FlanUL2_fp = data['fp']\n",
    "        FlanUL2_fn = data['fn']\n",
    "    print('=> load results from FlanUL2_eval_results_task2.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a03edc2-973a-4593-945c-c70bbefb0fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 0 - Precision: 0.96, Recall: 1.00\n",
      "Category 1 - Precision: 1.00, Recall: 0.98\n",
      "Category 2 - Precision: 0.98, Recall: 1.00\n",
      "Category 3 - Precision: 0.84, Recall: 0.92\n",
      "Category 4 - Precision: 0.49, Recall: 0.90\n",
      "Category 5 - Precision: 0.65, Recall: 0.56\n",
      "Category 6 - Precision: 0.42, Recall: 0.90\n",
      "Category 7 - Precision: 1.00, Recall: 0.32\n",
      "Category 8 - Precision: 0.78, Recall: 0.14\n",
      "Category 9 - Precision: 0.96, Recall: 0.98\n",
      "Category 10 - Precision: 0.78, Recall: 0.42\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "correct_corr = flanul2_out['correct_corr']  \n",
    "fp = flanul2_out['fp']  \n",
    "fn = flanul2_out['fn'] \n",
    "\n",
    "precision_per_class = {}\n",
    "recall_per_class = {}\n",
    "\n",
    "for category in range(11): \n",
    "    TP = correct_corr[category]\n",
    "    FP = fp[category]\n",
    "    FN = fn[category]\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN) \n",
    "    \n",
    "    precision_per_class[category] = precision\n",
    "    recall_per_class[category] = recall\n",
    "\n",
    "for category in range(11):\n",
    "    print(f\"Category {category} - Precision: {precision_per_class[category]:.2f}, Recall: {recall_per_class[category]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1902a019-28d0-4303-af90-2045aed9a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Books Accuracy: 0.96\n",
      "==> Music Accuracy: 1.0\n",
      "==> Video Accuracy: 0.96\n",
      "==> Toys Accuracy: 0.98\n",
      "==> Tools Accuracy: 0.88\n",
      "==> Office Products Accuracy: 0.56\n",
      "==> Electronics Accuracy: 0.92\n",
      "==> Kitchen Accuracy: 0.5\n",
      "==> Sports Accuracy: 0.24\n",
      "==> Shoes Accuracy: 1.0\n",
      "==> Health & Personal Care Accuracy: 0.5\n",
      "==> Total Accuracy: 0.7727272727272727\n",
      "==> Total Runtime: 375.2274160385132\n"
     ]
    }
   ],
   "source": [
    "# calculate the top-1 accuracy\n",
    "for key,val in id2label.items():\n",
    "    print(f'==> {val} Accuracy: {FlanUL2_correct_corr[int(key)]/FlanUL2_total_corr[int(key)]}')\n",
    "print(f'==> Total Accuracy: {np.sum(FlanUL2_correct_corr) / np.sum(FlanUL2_total_corr)}')\n",
    "print(f'==> Total Runtime: {FlanUL2_runtime_corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce4ba3de-0c44-4aff-8eaf-0fbff602680a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Books Accuracy: 0.96\n",
      "==> Music Accuracy: 1.0\n",
      "==> Video Accuracy: 0.98\n",
      "==> Toys Accuracy: 0.98\n",
      "==> Tools Accuracy: 0.94\n",
      "==> Office Products Accuracy: 0.92\n",
      "==> Electronics Accuracy: 0.96\n",
      "==> Kitchen Accuracy: 0.62\n",
      "==> Sports Accuracy: 0.58\n",
      "==> Shoes Accuracy: 1.0\n",
      "==> Health & Personal Care Accuracy: 0.62\n",
      "==> Total Accuracy: 0.8690909090909091\n",
      "==> Total Runtime: 375.2274160385132\n"
     ]
    }
   ],
   "source": [
    "# calculate the top-2 accuracy\n",
    "for key,val in id2label.items():\n",
    "    print(f'==> {val} Accuracy: {FlanUL2_correct_corr_top2[int(key)]/FlanUL2_total_corr[int(key)]}')\n",
    "print(f'==> Total Accuracy: {np.sum(FlanUL2_correct_corr_top2) / np.sum(FlanUL2_total_corr)}')\n",
    "print(f'==> Total Runtime: {FlanUL2_runtime_corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bead4698-80c3-403a-a9fc-893e62c29d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Books Accuracy: 0.98\n",
      "==> Music Accuracy: 1.0\n",
      "==> Video Accuracy: 0.98\n",
      "==> Toys Accuracy: 0.98\n",
      "==> Tools Accuracy: 1.0\n",
      "==> Office Products Accuracy: 0.96\n",
      "==> Electronics Accuracy: 0.98\n",
      "==> Kitchen Accuracy: 0.64\n",
      "==> Sports Accuracy: 0.84\n",
      "==> Shoes Accuracy: 1.0\n",
      "==> Health & Personal Care Accuracy: 0.68\n",
      "==> Total Accuracy: 0.9127272727272727\n",
      "==> Total Runtime: 375.2274160385132\n"
     ]
    }
   ],
   "source": [
    "# calculate the top-3 accuracy\n",
    "for key,val in id2label.items():\n",
    "    print(f'==> {val} Accuracy: {FlanUL2_correct_corr_top3[int(key)]/FlanUL2_total_corr[int(key)]}')\n",
    "print(f'==> Total Accuracy: {np.sum(FlanUL2_correct_corr_top3) / np.sum(FlanUL2_total_corr)}')\n",
    "print(f'==> Total Runtime: {FlanUL2_runtime_corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafee06f-f406-4294-b02f-48e610776f50",
   "metadata": {},
   "source": [
    "### Results\n",
    "|Model|top-1 acc|top-2 acc|top-3 acc|\n",
    "|-|-|-|-|\n",
    "|Flan-T5|0.724|0.849|0.913|\n",
    "|Flan-UL2|0.773|0.869|0.913|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d962601-0be1-4a6d-a451-c33358f40d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3530f5-3c97-4f42-a321-f32a6b4c027c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
